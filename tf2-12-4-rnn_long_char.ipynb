{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WakWakBird/MLS/blob/main/tf2-12-4-rnn_long_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "230c8c7a-13fd-46b3-c5b1-9c6330cfd846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "148eb9e5-9328-4104-f7ca-b3fc0d704f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m)         │         \u001b[38;5;34m5,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m)         │         \u001b[38;5;34m5,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m25\u001b[0m)         │           \u001b[38;5;34m650\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,850\u001b[0m (42.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,850</span> (42.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,850\u001b[0m (42.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,850</span> (42.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 - 8s - 1s/step - accuracy: 0.1447 - loss: 3.0266\n",
            "Epoch 2/100\n",
            "6/6 - 0s - 20ms/step - accuracy: 0.1894 - loss: 2.8418\n",
            "Epoch 3/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.2118 - loss: 2.6118\n",
            "Epoch 4/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.3412 - loss: 2.2145\n",
            "Epoch 5/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.4512 - loss: 1.8009\n",
            "Epoch 6/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.5447 - loss: 1.4496\n",
            "Epoch 7/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.6388 - loss: 1.1788\n",
            "Epoch 8/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.7053 - loss: 0.9302\n",
            "Epoch 9/100\n",
            "6/6 - 0s - 17ms/step - accuracy: 0.7765 - loss: 0.7452\n",
            "Epoch 10/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.7900 - loss: 0.6333\n",
            "Epoch 11/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8200 - loss: 0.5731\n",
            "Epoch 12/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8347 - loss: 0.5087\n",
            "Epoch 13/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8453 - loss: 0.4473\n",
            "Epoch 14/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8576 - loss: 0.3971\n",
            "Epoch 15/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8624 - loss: 0.3751\n",
            "Epoch 16/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8718 - loss: 0.3696\n",
            "Epoch 17/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8624 - loss: 0.3820\n",
            "Epoch 18/100\n",
            "6/6 - 0s - 20ms/step - accuracy: 0.8547 - loss: 0.3980\n",
            "Epoch 19/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8576 - loss: 0.3874\n",
            "Epoch 20/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8659 - loss: 0.3614\n",
            "Epoch 21/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8694 - loss: 0.3559\n",
            "Epoch 22/100\n",
            "6/6 - 0s - 22ms/step - accuracy: 0.8871 - loss: 0.3237\n",
            "Epoch 23/100\n",
            "6/6 - 0s - 22ms/step - accuracy: 0.8718 - loss: 0.3295\n",
            "Epoch 24/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8771 - loss: 0.3201\n",
            "Epoch 25/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8818 - loss: 0.3120\n",
            "Epoch 26/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8853 - loss: 0.2968\n",
            "Epoch 27/100\n",
            "6/6 - 0s - 21ms/step - accuracy: 0.8759 - loss: 0.3092\n",
            "Epoch 28/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8594 - loss: 0.3433\n",
            "Epoch 29/100\n",
            "6/6 - 0s - 21ms/step - accuracy: 0.8753 - loss: 0.3280\n",
            "Epoch 30/100\n",
            "6/6 - 0s - 22ms/step - accuracy: 0.8782 - loss: 0.3188\n",
            "Epoch 31/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8724 - loss: 0.3063\n",
            "Epoch 32/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8724 - loss: 0.3175\n",
            "Epoch 33/100\n",
            "6/6 - 0s - 26ms/step - accuracy: 0.8806 - loss: 0.3115\n",
            "Epoch 34/100\n",
            "6/6 - 0s - 26ms/step - accuracy: 0.8847 - loss: 0.3046\n",
            "Epoch 35/100\n",
            "6/6 - 0s - 49ms/step - accuracy: 0.8788 - loss: 0.3105\n",
            "Epoch 36/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8835 - loss: 0.2896\n",
            "Epoch 37/100\n",
            "6/6 - 0s - 48ms/step - accuracy: 0.8829 - loss: 0.2874\n",
            "Epoch 38/100\n",
            "6/6 - 0s - 19ms/step - accuracy: 0.8794 - loss: 0.2883\n",
            "Epoch 39/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8829 - loss: 0.2834\n",
            "Epoch 40/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8924 - loss: 0.2759\n",
            "Epoch 41/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8835 - loss: 0.2768\n",
            "Epoch 42/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8859 - loss: 0.2755\n",
            "Epoch 43/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8865 - loss: 0.2762\n",
            "Epoch 44/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8882 - loss: 0.2778\n",
            "Epoch 45/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8853 - loss: 0.2660\n",
            "Epoch 46/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8865 - loss: 0.2708\n",
            "Epoch 47/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8776 - loss: 0.2741\n",
            "Epoch 48/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8847 - loss: 0.2850\n",
            "Epoch 49/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8871 - loss: 0.2749\n",
            "Epoch 50/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8918 - loss: 0.2800\n",
            "Epoch 51/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8900 - loss: 0.2729\n",
            "Epoch 52/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8865 - loss: 0.2712\n",
            "Epoch 53/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8918 - loss: 0.2671\n",
            "Epoch 54/100\n",
            "6/6 - 0s - 26ms/step - accuracy: 0.8900 - loss: 0.2630\n",
            "Epoch 55/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8865 - loss: 0.2699\n",
            "Epoch 56/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8859 - loss: 0.2642\n",
            "Epoch 57/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8841 - loss: 0.2688\n",
            "Epoch 58/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8865 - loss: 0.2706\n",
            "Epoch 59/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8865 - loss: 0.2672\n",
            "Epoch 60/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8865 - loss: 0.2641\n",
            "Epoch 61/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8876 - loss: 0.2620\n",
            "Epoch 62/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8906 - loss: 0.2621\n",
            "Epoch 63/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8865 - loss: 0.2623\n",
            "Epoch 64/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8894 - loss: 0.2554\n",
            "Epoch 65/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8900 - loss: 0.2543\n",
            "Epoch 66/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8918 - loss: 0.2535\n",
            "Epoch 67/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8918 - loss: 0.2510\n",
            "Epoch 68/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8876 - loss: 0.2593\n",
            "Epoch 69/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8924 - loss: 0.2563\n",
            "Epoch 70/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8888 - loss: 0.2546\n",
            "Epoch 71/100\n",
            "6/6 - 0s - 25ms/step - accuracy: 0.8894 - loss: 0.2565\n",
            "Epoch 72/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8876 - loss: 0.2528\n",
            "Epoch 73/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8900 - loss: 0.2539\n",
            "Epoch 74/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8894 - loss: 0.2518\n",
            "Epoch 75/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8924 - loss: 0.2591\n",
            "Epoch 76/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8912 - loss: 0.2466\n",
            "Epoch 77/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8871 - loss: 0.2545\n",
            "Epoch 78/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8882 - loss: 0.2511\n",
            "Epoch 79/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8900 - loss: 0.2492\n",
            "Epoch 80/100\n",
            "6/6 - 0s - 25ms/step - accuracy: 0.8912 - loss: 0.2507\n",
            "Epoch 81/100\n",
            "6/6 - 0s - 22ms/step - accuracy: 0.8918 - loss: 0.2472\n",
            "Epoch 82/100\n",
            "6/6 - 0s - 22ms/step - accuracy: 0.8876 - loss: 0.2478\n",
            "Epoch 83/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8882 - loss: 0.2492\n",
            "Epoch 84/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8876 - loss: 0.2500\n",
            "Epoch 85/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8882 - loss: 0.2481\n",
            "Epoch 86/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8894 - loss: 0.2491\n",
            "Epoch 87/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8871 - loss: 0.2474\n",
            "Epoch 88/100\n",
            "6/6 - 0s - 26ms/step - accuracy: 0.8918 - loss: 0.2482\n",
            "Epoch 89/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8924 - loss: 0.2473\n",
            "Epoch 90/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8882 - loss: 0.2455\n",
            "Epoch 91/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8941 - loss: 0.2486\n",
            "Epoch 92/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8865 - loss: 0.2467\n",
            "Epoch 93/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8918 - loss: 0.2491\n",
            "Epoch 94/100\n",
            "6/6 - 0s - 14ms/step - accuracy: 0.8853 - loss: 0.2501\n",
            "Epoch 95/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8876 - loss: 0.2473\n",
            "Epoch 96/100\n",
            "6/6 - 0s - 22ms/step - accuracy: 0.8924 - loss: 0.2436\n",
            "Epoch 97/100\n",
            "6/6 - 0s - 24ms/step - accuracy: 0.8859 - loss: 0.2469\n",
            "Epoch 98/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8853 - loss: 0.2490\n",
            "Epoch 99/100\n",
            "6/6 - 0s - 23ms/step - accuracy: 0.8941 - loss: 0.2440\n",
            "Epoch 100/100\n",
            "6/6 - 0s - 15ms/step - accuracy: 0.8912 - loss: 0.2478\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step\n",
            "m you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea."
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 입력 문장\n",
        "sentence = (\n",
        "    \"if you want to build a ship, don't drum up people together to \"\n",
        "    \"collect wood and don't assign them tasks and work, but rather \"\n",
        "    \"teach them to long for the endless immensity of the sea.\"\n",
        ")\n",
        "\n",
        "# 고유 문자 집합 및 딕셔너리 생성\n",
        "char_set = list(set(sentence))\n",
        "char_dic = {w: i for i, w in enumerate(char_set)}\n",
        "\n",
        "# 하이퍼파라미터\n",
        "data_dim = len(char_set)             # 입력 차원 (문자 개수)\n",
        "hidden_size = len(char_set)          # LSTM 유닛 수 (출력 클래스 수와 동일)\n",
        "num_classes = len(char_set)          # 분류할 문자 수\n",
        "sequence_length = 10\n",
        "learning_rate = 0.1\n",
        "\n",
        "# 시퀀스 데이터 생성\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(len(sentence) - sequence_length):\n",
        "    x_str = sentence[i:i + sequence_length]\n",
        "    y_str = sentence[i + 1:i + sequence_length + 1]\n",
        "\n",
        "    x = [char_dic[c] for c in x_str]\n",
        "    y = [char_dic[c] for c in y_str]\n",
        "\n",
        "    dataX.append(x)\n",
        "    dataY.append(y)\n",
        "\n",
        "# 텐서 형식으로 변환 (One-hot)\n",
        "X_one_hot = tf.one_hot(dataX, num_classes)   # (N, seq_len, num_classes)\n",
        "Y_one_hot = tf.one_hot(dataY, num_classes)   # (N, seq_len, num_classes)\n",
        "\n",
        "# 모델 구성\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(units=num_classes, input_shape=(sequence_length, num_classes), return_sequences=True),\n",
        "    tf.keras.layers.LSTM(units=num_classes, return_sequences=True),\n",
        "    tf.keras.layers.TimeDistributed(\n",
        "        tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
        "    )\n",
        "])\n",
        "\n",
        "# 컴파일\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 학습\n",
        "model.fit(X_one_hot, Y_one_hot, epochs=100, verbose=2)\n",
        "\n",
        "# 예측\n",
        "results = model.predict(X_one_hot)\n",
        "for t, result in enumerate(results):\n",
        "    index = np.argmax(result, axis=1)\n",
        "    if t == 0:\n",
        "        print(''.join([char_set[i] for i in index]), end='')\n",
        "    else:\n",
        "        print(char_set[index[-1]], end='')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}